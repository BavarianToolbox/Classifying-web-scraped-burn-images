# Classifying-web-scraped-burn-images

This was an experimental exercise to get an understanding of the in's and out's of clasifying web-scraped first, second, and third degree burn images using deep learning. Specifically, I tried to answer the following questions:

- What parameters are best suited for classifying burn images (input image size, image transforms and augmentations, etc.)

- Which CNN model architecture performs best (ResNet, DenseNet, VGG)

- How do different model architectures perform across the different classes

- Does un-freezing the network improve training, or are the pre-trained weights sufficient to perform accurately classify the burns?

The complete analysis can be found in the (notebook)[https://github.com/BavarianToolbox/Classifying-web-scraped-burn-images/blob/master/classifying_web_scraped_burn_images.ipynb].
